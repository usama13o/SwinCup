{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install medmnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedMNIST v2.1.0 @ https://github.com/MedMNIST/MedMNIST/\n"
     ]
    }
   ],
   "source": [
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pathmnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "root=\"/home/uz1/DATA!/medmnist\"\n",
    "#if not there create it \n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "# # load the data\n",
    "# train_dataset = DataClass(split='train', transform=data_transform, download=download,root=root)\n",
    "# test_dataset = DataClass(split='test', transform=data_transform, download=download,root=root)\n",
    "\n",
    "# pil_dataset = DataClass(split='train', download=download,root=root)\n",
    "\n",
    "# # encapsulate data into dataloader form\n",
    "# train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "# test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine multiple datasets into one Class \n",
    "class ConcatDataset(medmnist.dataset.MedMNIST2D):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "        #create e dictionary mapping between the dataset index in datasets and the class index in the combined dataset\n",
    "        class_index = {}\n",
    "        for i,d in enumerate(datasets):\n",
    "            for j in range(len(d.info['label'])):\n",
    "                class_index[i,j] = sum(len(d.info['label']) for d in datasets[:i]) + j\n",
    "        self.class_index = class_index\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        #based on i and total number of samples in all datasets, determine which dataset to get the sample from\n",
    "        for y,d in enumerate(self.datasets):\n",
    "            # print(\"looking in dataset\",d,\" for sample\",i)\n",
    "            if i < len(d):\n",
    "                x,z = d[i]\n",
    "                # print(z)\n",
    "                if len(z) > 1:\n",
    "                    z =  np.array(0) if sum(z) == 0 else np.array(1)\n",
    "                # if image in index 1 has 1 channel, repeat it 3 times then reutrn it\n",
    "                if x.shape[0] == 1:\n",
    "                    return x.repeat(3,1,1), self.class_index[(y,int(z))]\n",
    "                return x, self.class_index[(y,int(z))]\n",
    "            i -= len(d)\n",
    "        raise IndexError('index out of range')\n",
    "\n",
    "    def __len__(self):\n",
    "        #sum of all the lengths of the datasets\n",
    "        return sum(len(d) for d in self.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/octmnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/bloodmnist.npz\n",
      "291241\n"
     ]
    }
   ],
   "source": [
    "from medmnist.dataset import PathMNIST, BreastMNIST,OCTMNIST,ChestMNIST,PneumoniaMNIST,DermaMNIST,RetinaMNIST,BloodMNIST\n",
    "\n",
    "# load the datasets\n",
    "pathmnist = PathMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "breastmnist = BreastMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "octmnist = OCTMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "chestmnist = ChestMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "pneumoniamnist = PneumoniaMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "dermamnist = DermaMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "retinamnist = RetinaMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    "bloodmnist = BloodMNIST(split='train', transform=data_transform, download=download,root=root)\n",
    " # combine the datasets\n",
    "combined_dataset = ConcatDataset(pathmnist,breastmnist,octmnist,chestmnist,pneumoniamnist,dermamnist,retinamnist,bloodmnist)\n",
    "\n",
    "#print lenght of the combined dataset\n",
    "print(len(combined_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes in each dataset\n",
      "9\n",
      "2\n",
      "4\n",
      "14\n",
      "2\n",
      "7\n",
      "5\n",
      "8\n",
      "total number of classes in combined dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each d in datasets print number of calsses \n",
    "print(\"number of classes in each dataset\")\n",
    "for d in combined_dataset.datasets:\n",
    "    print(len(d.info['label']))\n",
    "# sum of all number of classes in d of datasets\n",
    "print(\"total number of classes in combined dataset\")\n",
    "sum(len(d.info['label']) for d in combined_dataset.datasets)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bf7c8448272c4cbdce3f78384e0b31dc492bbd9290e96311fca142ad432e9ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
