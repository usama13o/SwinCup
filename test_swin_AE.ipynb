{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "\n",
    "from torch.utils.data.dataloader import T\n",
    "import numpy as np\n",
    "# TODO fix mkl problem \n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import pywick \n",
    "from pywick.models.segmentation import deeplab_v3_plus\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from utils.util import json_file_to_dict_args, json_file_to_pyobj,get_tags\n",
    "from dataio.loader import get_dataset, get_dataset_path\n",
    "from dataio.transformation import get_dataset_transformation\n",
    "from torch.utils.data import DataLoader, dataset\n",
    "from pywick.modules import ModuleTrainer\n",
    "import pywick.metrics as pwm\n",
    "from utils.error_logger import ErrorLogger\n",
    "import torch\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from utils.visualiser import Visualiser\n",
    "from utils.error_logger import ErrorLogger\n",
    "import pytorch_lightning as pl\n",
    "from models import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "class DivideIntoPatches:\n",
    "    def __init__(self, patch_size):\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        height, width = img.shape[-2:]\n",
    "        patches = []\n",
    "        for i in range(0, height - self.patch_size + 1, self.patch_size):\n",
    "            for j in range(0, width - self.patch_size + 1, self.patch_size):\n",
    "                patches.append(img[ :, i:i + self.patch_size, j:j + self.patch_size])\n",
    "        return torch.stack(patches, dim=0)\n",
    "class ResizePatches:\n",
    "    def __init__(self,pz):\n",
    "        self.patch_size = pz\n",
    "    def __call__(self, img):\n",
    "        imgs = img.reshape(-1,img.shape[-3],img.shape[-2],img.shape[-1])\n",
    "        return torch.nn.functional.interpolate(imgs, size=(self.patch_size,self.patch_size), mode='bilinear', align_corners=False)\n",
    "def get_data(pz = 80, img_size=224, bs=None,split=\"train\",pz_=None):\n",
    "    patch_size = pz\n",
    "    img_size = img_size\n",
    "    num_patches = (img_size // patch_size) ** 2\n",
    "    bs = 120 // num_patches \n",
    "    if num_patches <5:\n",
    "        bs=bs//8\n",
    "    bs = 1 if bs == 0 else bs\n",
    "    print(\"config:\\n\", \"patch_size:\", patch_size, \"img_size:\", img_size, \"num_patches:\", num_patches, \"bs:\", bs)\n",
    "    if pz_ is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ConvertImageDtype(torch.float),\n",
    "            DivideIntoPatches(patch_size=patch_size), # takes an image tensor and returns a list of patches stacked as (H // patch_size **2 x H x W x C)\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        DivideIntoPatches(patch_size=patch_size), # takes an image tensor and returns a list of patches stacked as (H // patch_size **2 x H x W x C)\n",
    "        ResizePatches(pz=pz_)\n",
    "        ])\n",
    "\n",
    "    # data = wss_dataset_class(\"/home/uz1/data/wsss/train/1.training\", 'all',\n",
    "                            #  transform)\n",
    "    # data = HDF5Dataset(\"/home/uz1/DATA!/pcam/pcam/training_split.h5\",\"/home/uz1/DATA!/pcam/Labels/Labels/camelyonpatch_level_2_split_train_y.h5\",transform=transform)\n",
    "    from medmnist.dataset import PathMNIST, BreastMNIST,OCTMNIST,ChestMNIST,PneumoniaMNIST,DermaMNIST,RetinaMNIST,BloodMNIST,TissueMNIST,OrganAMNIST,OrganCMNIST,OrganSMNIST\n",
    "    # using a unified ataset of medmnist\n",
    "    data = PathMNIST(root='/home/uz1/DATA!/medmnist', split=split,transform=transform)\n",
    "    loader = DataLoader(data, batch_size=bs, drop_last=True, num_workers=14)\n",
    "    return data,loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/losses/self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/datamodules/experience_source.py:18: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  warn_missing_pkg(\"gym\")\n"
     ]
    }
   ],
   "source": [
    "from models.networks.swin_transformer import SwinTransformer\n",
    "# create a class that inherits from SwinTransformer\n",
    "class SwinTransformerAE(SwinTransformer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img_size (int | tuple(int)): Input image size. Default 224\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "        \"\"\"\n",
    "    def __init__(self, img_size, patch_size=4, enc_out = 256,in_chans=3, embed_dim=96,out_indices = (0,1) ,depths=[4, 12], num_heads=[12, 24], window_size=4, mlp_ratio=4., qkv_bias=True, qk_scale=None, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.,  ape=False, patch_norm=True, use_checkpoint=False):\n",
    "        super().__init__(img_size = img_size, patch_size = patch_size,out_indices = out_indices, in_chans = in_chans, embed_dim = embed_dim, depths = depths, num_heads = num_heads, window_size = window_size, mlp_ratio = mlp_ratio, qkv_bias = qkv_bias, qk_scale = qk_scale, drop_rate = drop_rate, attn_drop_rate = attn_drop_rate, drop_path_rate = drop_path_rate,  ape = ape, patch_norm = patch_norm, use_checkpoint = use_checkpoint)\n",
    "        self.linear = torch.nn.Linear(int((img_size // 8)**2 * 192), enc_out)\n",
    "    def forward_features(self, x):\n",
    "        outs = super().forward_features(x)\n",
    "        out = torch.flatten(outs[-1],1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    def forward(self, x):\n",
    "        x = super().forward_features(x)\n",
    "        return x\n",
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    "    ResNetDecoder,\n",
    "    DecoderBlock,\n",
    ")\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class Interpolate(nn.Module):\n",
    "    \"\"\"nn.Module wrapper for F.interpolate.\"\"\"\n",
    "\n",
    "    def __init__(self, size=None, scale_factor=None):\n",
    "        super().__init__()\n",
    "        self.size, self.scale_factor = size, scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, size=self.size, scale_factor=self.scale_factor)\n",
    "def resize_conv1x1(in_planes, out_planes, scale=1):\n",
    "    \"\"\"upsample + 1x1 convolution with padding to avoid checkerboard artifact.\"\"\"\n",
    "    if scale == 1:\n",
    "        return conv1x1(in_planes, out_planes)\n",
    "    return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution.\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class Resdecoder(nn.Module):\n",
    "    def __init__(self, x,latent_dim=256, input_height=224, first_conv=False, maxpool1=False):\n",
    "        # super().__init__(   DecoderBlock, [2, 2, 2, 2],latent_dim=latent_dim, input_height=input_height, first_conv=first_conv, maxpool1=maxpool1)\n",
    "        super().__init__()\n",
    "        self.block = DecoderBlock\n",
    "        self.latent_dim = latent_dim\n",
    "        self.expansion = self.block.expansion\n",
    "        self.first_conv = first_conv\n",
    "        self.maxpool1 = maxpool1\n",
    "        self.input_height = input_height\n",
    "        self.layers = [2, 2, 2, 2]\n",
    "        self.upscale_factor = 8\n",
    "        \n",
    "\n",
    "        _, self.c, self.h, self.w = x.shape\n",
    "        block = self.block\n",
    "        layers = self.layers\n",
    "        out_put_shape = self.c # * self.h * self.w\n",
    "        self.linear = torch.nn.Linear(self.latent_dim, out_put_shape * self.h * self.w)\n",
    "        self.inplanes = out_put_shape\n",
    "\n",
    "\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 256, layers[0], scale=2)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], scale=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], scale=2)\n",
    "\n",
    "        if self.maxpool1:\n",
    "            self.layer4 = self._make_layer(block, 64, layers[3], scale=2)\n",
    "            self.upscale_factor *= 2\n",
    "        else:\n",
    "            self.layer4 = self._make_layer(block, 64, layers[3])\n",
    "\n",
    "        if self.first_conv:\n",
    "            self.upscale = Interpolate(scale_factor=2)\n",
    "            self.upscale_factor *= 2\n",
    "        else:\n",
    "            self.upscale = Interpolate(scale_factor=1)\n",
    "\n",
    "        # interpolate after linear layer using scale factor\n",
    "        self.upscale1 = Interpolate(size=self.input_height // self.upscale_factor)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64 * block.expansion, 3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    def _make_layer(self, block, planes, blocks, scale=1):\n",
    "        upsample = None\n",
    "        if scale != 1 or self.inplanes != planes * block.expansion:\n",
    "            upsample = nn.Sequential(\n",
    "                resize_conv1x1(self.inplanes, planes * block.expansion, scale),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, scale, upsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        x = x.view(x.size(0), self.c, self.h, self.w)\n",
    "        x = self.upscale1(x)\n",
    "        # print('in to l1',x.shape)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.upscale(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      " patch_size: 112 img_size: 224 num_patches: 4 bs: 3\n",
      "using input height  112  and latent dim  256  and enc_out_dim  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525553989/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:132: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:36: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return conv3x3(in_planes, out_planes)\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:37: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv3x3(in_planes, out_planes))\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pytorch_lightning/core/module.py:378: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  \"You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(64128.8555, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32, window_size=4,patch_size = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.input_height = input_height\n",
    "        print(\"using input height \",input_height,\" and latent dim \",latent_dim,\" and enc_out_dim \",enc_out_dim)\n",
    "        self.encoder = SwinTransformerAE(img_size=input_height,patch_size = patch_size,window_size= window_size,enc_out = enc_out_dim)\n",
    "\n",
    "    \n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "\n",
    "        #simulate a pass through the encoder \n",
    "        x = self.encoder.forward(torch.randn(1,3,input_height,input_height))\n",
    "        self.decoder = Resdecoder(x[-1],latent_dim=latent_dim,input_height=input_height,first_conv=False,maxpool1=False)\n",
    "\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def gaussian_likelihood(self, mean, logscale, sample):\n",
    "        scale = torch.exp(logscale)\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "        log_pxz = dist.log_prob(sample)\n",
    "        return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu),\n",
    "                                       torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # print(batch)\n",
    "        x, _ = batch\n",
    "        #if channels are less than 3, repeat channels\n",
    "        # print(x.shape)\n",
    "        # if x.shape[1] < 3:\n",
    "        #     x = x.repeat(1, 3, 1, 1)\n",
    "        # print('x in training step',x.shape)\n",
    "        if x.dim() >4: # b,16,3,h,w -> b*16,3,h,w\n",
    "            x = x.view(-1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder.forward_features(x)\n",
    "        # print('x_encoded in training step',x_encoded.shape)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "        # detect nan \n",
    "        if torch.isnan(mu).any() or torch.isnan(log_var).any():\n",
    "            print(\"NAN in mu or log_var\")\n",
    "            print(mu)\n",
    "            print(log_var)\n",
    "            print(x_encoded,x_encoded.shape)\n",
    "            print(x,x.shape)\n",
    "            raise ValueError(\"NAN in mu or log_var\")\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "        # print('z in training step',z.shape)\n",
    "        x_hat = self.decoder(z)\n",
    "        # print('x_hat in training step',x_hat.shape)\n",
    "        # reconstruction loss\n",
    "        recon_loss_ = self.gaussian_likelihood(x_hat, self.log_scale, x) # old recon_loss \n",
    "        # print(recon_loss.shape)\n",
    "        recon_loss = torch.nn.MSELoss()(x_hat,x)\n",
    "        # print(recon_loss.shape)\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss_) # with old recon_loss\n",
    "        # elbo = (kl + recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo': elbo,\n",
    "            'kl': kl.mean(),\n",
    "            'recon_loss_mse': recon_loss.mean(),\n",
    "            'recon_loss_gl': recon_loss_.mean(),\n",
    "            'reconstruction': recon_loss.mean(),\n",
    "            'kl': kl.mean(),\n",
    "        })\n",
    "\n",
    "        return elbo\n",
    "    def forward(self,batch):\n",
    "        x, _ = batch if len(batch)==2 else batch , 0\n",
    "        #if channels are less than 3, repeat channels\n",
    "        # print(x.shape)\n",
    "        # if x.shape[1] < 3:\n",
    "        #     x = x.repeat(1, 3, 1, 1)\n",
    "        # print('x in training step',x.shape)\n",
    "        if x.dim() >4: # b,16,3,h,w -> b*16,3,h,w\n",
    "            x = x.view(-1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder.forward_features(x)\n",
    "        # print('x_encoded in training step',x_encoded.shape)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "        # detect nan \n",
    "        if torch.isnan(mu).any() or torch.isnan(log_var).any():\n",
    "            print(\"NAN in mu or log_var\")\n",
    "            print(mu)\n",
    "            print(log_var)\n",
    "            print(x_encoded,x_encoded.shape)\n",
    "            raise ValueError(\"NAN in mu or log_var\")\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "        # print('z in training step',z.shape)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        #if channels are less than 3, repeat channels\n",
    "        # print(x.shape)\n",
    "        # if x.shape[1] < 3:\n",
    "        #     x = x.repeat(1, 3, 1, 1)\n",
    "        # print(x.shape)\n",
    "        if x.dim() >4: # b,16,3,h,w -> b*16,3,h,w\n",
    "            x = x.view(-1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder.forward_features(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss_ = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "        # print(recon_loss.shape)\n",
    "        recon_loss = torch.nn.MSELoss()(x_hat,x)\n",
    "\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss_) # with old recon_loss\n",
    "        # elbo = (kl + recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'val_elbo': elbo,\n",
    "            'val_kl': kl.mean(),\n",
    "            'val_recon_loss_': recon_loss.mean(),\n",
    "            'val_recon_loss': recon_loss_.mean(),\n",
    "            'val_reconstruction': recon_loss.mean(),\n",
    "            'val_kl': kl.mean(),\n",
    "        })\n",
    "\n",
    "        return elbo\n",
    "\n",
    "\n",
    "data , loader = get_data(pz = 112, img_size=  224)\n",
    "v = VAE(input_height=data[0][0].shape[-1],window_size =28, patch_size = 4)\n",
    "v.training_step(data[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lets dfine an nn.Module to wrap the encoder and decoder\n",
    "class AE(nn.Module):\n",
    "    def __init__(self,inp):\n",
    "        super().__init__()\n",
    "        self.encoder = SwinTransformerAE(inp,4)\n",
    "        self.decoder = Resdecoder(latent_dim=256,input_height=inp,first_conv=False,maxpool1=False)\n",
    "    def init_params(self,x):\n",
    "        # print('in to encoder ',x.shape)\n",
    "        x = self.encoder.forward(x)\n",
    "        # print('out from encoder ',x[-1].shape)\n",
    "        self.decoder.init_params(x[-1])\n",
    "    def forward(self,x):\n",
    "        # print('in to encoder ',x.shape)\n",
    "        out = self.encoder.forward_features(x)\n",
    "        # print('out from encoder ',out.shape)\n",
    "        \n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "# model = AE(inp=data[0][0].shape[-1])\n",
    "# model.init_params(data[0][0])\n",
    "# model(data[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "class AEpl(pl.LightningModule):\n",
    "    def __init__(self,inp,lr):\n",
    "        \"\"\"This is a class for training an autoencoder with pytorch lightning.\n",
    "\n",
    "        Args:\n",
    "            inp (int): number of input features\n",
    "            lr (float): learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = AE(inp)\n",
    "        self.loss = nn.MSELoss()\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    #before train\n",
    "    def init_params(self,x):\n",
    "        self.model.init_params(x)\n",
    "    def to_cuda(self):\n",
    "        self.model.encoder.cuda()\n",
    "        self.model.decoder.cuda()\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,_ = batch\n",
    "        if len(x.shape) > 4:\n",
    "            x = x.reshape(-1,x.shape[-3],x.shape[-2],x.shape[-1])\n",
    "        out = self.forward(x)\n",
    "        loss = self.loss(x,out)\n",
    "        self.log('train_loss',loss)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return opt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#`` lr logging\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from callbacks import  TestReconCallback_vae,TestReconCallback_ae\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "def get_callbacks():\n",
    "    callbacks = []\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    callbacks.append(lr_monitor)\n",
    "\n",
    "    # save checkpoint on last epoch only\n",
    "    ckpt = ModelCheckpoint(f\"/home/uz1/projects/GCN/logging/swin_vae/{datetime.datetime.now().strftime('%Y_%m_%d')}\",\n",
    "                        monitor=\"elbo\",\n",
    "                        save_weights_only=True)\n",
    "    callbacks.append(ckpt)\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      " patch_size: 24 img_size: 224 num_patches: 81 bs: 1\n",
      "using input height  24  and latent dim  256  and enc_out_dim  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input height  64  and latent dim  256  and enc_out_dim  512\n",
      "transfering from  64  To  24\n",
      "config:\n",
      " patch_size: 24 img_size: 224 num_patches: 81 bs: 1\n",
      "new data size torch.Size([81, 3, 64, 64])\n",
      "config:\n",
      " patch_size: 32 img_size: 224 num_patches: 49 bs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/lightning_lite/plugins/environments/slurm.py:172: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/uz1/miniconda3/envs/ML/lib/python3.7/site-pack ...\n",
      "  category=PossibleUserWarning,\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/applications/slurm-22.05.2/bin/srun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/lightning_lite/plugins/environments/slurm.py:172: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/uz1/miniconda3/envs/ML/lib/python3.7/site-pack ...\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/applications/slurm-22.05.2/bin/srun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:606: UserWarning: Checkpoint directory /home/uz1/projects/GCN/logging/swin_vae/2023_03_16 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | encoder | SwinTransformerAE | 74.6 M\n",
      "1 | fc_mu   | Linear            | 131 K \n",
      "2 | fc_var  | Linear            | 131 K \n",
      "3 | decoder | Resdecoder        | 6.8 M \n",
      "----------------------------------------------\n",
      "81.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "81.7 M    Total params\n",
      "326.832   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f349111cb68a477aa3aa0825541ed084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7b983fe56a4192b3020de8e6047693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data \n",
    "\n",
    "data , loader = get_data(pz = 24, img_size=  224)\n",
    "#clbs \n",
    "# add test for mid-train recon viewing\n",
    "test = [data[x][0] for x in random.sample(range(len(data)), 1)]\n",
    "\n",
    "test = torch.stack(test, 0).squeeze()\n",
    "testRecon = TestReconCallback_vae(test)\n",
    "callbacks = get_callbacks()\n",
    "callbacks.append(testRecon)\n",
    "# train \n",
    "# model = AEpl(inp=data[0][0].shape[-1],lr=1e-3)\n",
    "inp = data[0][0].shape[-1]\n",
    "model2 = VAE(input_height=inp,window_size =28, patch_size = 4)\n",
    "model = model2.load_from_checkpoint(\"/home/uz1/projects/GCN/logging/swin_vae/2023_03_14/epoch=4-step=44995.ckpt\",)\n",
    "print(\"transfering from \",model.hparams.input_height, ' To ', model2.hparams.input_height)\n",
    "#check if hparams are the same\n",
    "if model.hparams.input_height != model2.hparams.input_height:\n",
    "    # take our current patch size and resize it to the new input size\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        DivideIntoPatches(patch_size=model2.hparams.input_height), # takes an image tensor and returns a list of patches stacked as (H // patch_size **2 x H x W x C)\n",
    "        ResizePatches(model.hparams.input_height), # takes a list of patches and returns a list of patches resized to (patch_size, patch_size)\n",
    "        ])\n",
    "    data,loader= get_data(pz = model2.hparams.input_height, img_size= 224,pz_=model.hparams.input_height,split='test')\n",
    "    #readjust callbacks \n",
    "    test = [data[x][0] for x in random.sample(range(len(data)), 1)]\n",
    "    callbacks = get_callbacks()\n",
    "    test = torch.stack(test, 0).squeeze()\n",
    "    testRecon = TestReconCallback_vae(test)\n",
    "    callbacks.append(testRecon)\n",
    "    print('new data size',data[0][0].shape)\n",
    "# model.to_cuda()\n",
    "_,test_loader = get_data(pz = 32, img_size=  224,split='val',pz_=model.hparams.input_height)\n",
    "# build trainer\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1, callbacks=callbacks )\n",
    "# train\n",
    "trainer.fit(model, loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test results of recondtruction\n",
    "model.eval()\n",
    "import random\n",
    "i= random.randint(0,len(data))\n",
    "with torch.no_grad():\n",
    "    x = data[i]\n",
    "    x_hat = model(x)\n",
    "    x_hat = x_hat.squeeze(0)\n",
    "    x_hat = x_hat.cpu().numpy()\n",
    "    x = x[0].cpu().numpy()\n",
    "    x_hat = np.moveaxis(x_hat, 1, -1)\n",
    "    x = np.moveaxis(x, 1, -1)\n",
    "    print(x_hat.shape)\n",
    "\n",
    "# plot - handle multiple images , x is multiple images\n",
    "# for tht length of x.shape[0] \n",
    "for i in range(x.shape[0]):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[i])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(x_hat[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      " patch_size: 80 img_size: 224 num_patches: 4 bs: 3\n",
      "using input height  16  and latent dim  256  and enc_out_dim  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:132: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:36: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return conv3x3(in_planes, out_planes)\n",
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/pl_bolts/models/autoencoders/components.py:37: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  return nn.Sequential(Interpolate(scale_factor=scale), conv3x3(in_planes, out_planes))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input height  64  and latent dim  256  and enc_out_dim  512\n",
      "given num_patches:  4  num_points:  1333\n",
      "Using a VAE with h= 224 and p(z)= 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fdfa131b4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _releaseLock at 0x7fdfa131b4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _releaseLock at 0x7fdfa131b4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fde4197f560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7fdfa131b4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _releaseLock at 0x7fdfa131b4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fde4197f560>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/uz1/miniconda3/envs/ML/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Fitting Kmeans:   1%|          | 9/1333 [01:58<4:50:31, 13.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_2185381/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2856134949.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">37</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_2185381/2856134949.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_2185381/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4023865820.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">29</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward_features</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_2185381/4023865820.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/projects/codeServerEPI/models/networks/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">swin_transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">651</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward_features</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">648 │   │   </span>outs = []                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">649 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_layers):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">650 │   │   │   </span>layer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layers[i]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>651 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x_out, x = layer(x)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">652 │   │   │   </span>H = W = sqrt(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(x_out.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]))                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">653 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.out_indices:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">654 │   │   │   │   </span>norm_layer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f'norm{</span>i<span style=\"color: #808000; text-decoration-color: #808000\">}'</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/projects/codeServerEPI/models/networks/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">swin_transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">411</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">408 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_checkpoint:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">409 │   │   │   │   </span>x = checkpoint.checkpoint(blk, x)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">410 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>411 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>x = blk(x)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">412 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.downsample <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 │   │   │   </span>x_dwon = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.downsample(x)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">414 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> x,x_dwon                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/projects/codeServerEPI/models/networks/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">swin_transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">268</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   </span>x_windows = x_windows.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size, C)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># nW*B, </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267 │   │   # W-MSA/SW-MSA</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>268 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_windows = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn(x_windows, mask=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn_mask)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># nW*B, window_size*wi</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270 │   │   # merge windows</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">271 │   │   </span>attn_windows = attn_windows.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size, C)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/projects/codeServerEPI/models/networks/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">swin_transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">137</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   </span>relative_position_bias = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.relative_position_bias_table[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.relative_positio   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window_size[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.window   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   </span>relative_position_bias = relative_position_bias.permute(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>).contiguous()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>137 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn = attn + relative_position_bias.unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mask <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   │   </span>nW = mask.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_2185381/\u001b[0m\u001b[1;33m2856134949.py\u001b[0m:\u001b[94m37\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_2185381/2856134949.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_2185381/\u001b[0m\u001b[1;33m4023865820.py\u001b[0m:\u001b[94m29\u001b[0m in \u001b[92mforward_features\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_2185381/4023865820.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/projects/codeServerEPI/models/networks/\u001b[0m\u001b[1;33mswin_transformer.py\u001b[0m:\u001b[94m651\u001b[0m in \u001b[92mforward_features\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   │   \u001b[0mouts = []                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m649 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mself\u001b[0m.num_layers):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m650 \u001b[0m\u001b[2m│   │   │   \u001b[0mlayer = \u001b[96mself\u001b[0m.layers[i]                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m651 \u001b[2m│   │   │   \u001b[0mx_out, x = layer(x)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m652 \u001b[0m\u001b[2m│   │   │   \u001b[0mH = W = sqrt(\u001b[96mint\u001b[0m(x_out.shape[\u001b[94m1\u001b[0m]))                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m653 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m i \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.out_indices:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m654 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnorm_layer = \u001b[96mgetattr\u001b[0m(\u001b[96mself\u001b[0m, \u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mnorm\u001b[0m\u001b[33m{\u001b[0mi\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/projects/codeServerEPI/models/networks/\u001b[0m\u001b[1;33mswin_transformer.py\u001b[0m:\u001b[94m411\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m408 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_checkpoint:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m409 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mx = checkpoint.checkpoint(blk, x)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m410 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m411 \u001b[2m│   │   │   │   \u001b[0mx = blk(x)                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m412 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.downsample \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m\u001b[2m│   │   │   \u001b[0mx_dwon = \u001b[96mself\u001b[0m.downsample(x)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m414 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m x,x_dwon                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/projects/codeServerEPI/models/networks/\u001b[0m\u001b[1;33mswin_transformer.py\u001b[0m:\u001b[94m268\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   \u001b[0mx_windows = x_windows.view(-\u001b[94m1\u001b[0m, \u001b[96mself\u001b[0m.window_size * \u001b[96mself\u001b[0m.window_size, C)  \u001b[2m# nW*B, \u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# W-MSA/SW-MSA\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m268 \u001b[2m│   │   \u001b[0mattn_windows = \u001b[96mself\u001b[0m.attn(x_windows, mask=\u001b[96mself\u001b[0m.attn_mask)  \u001b[2m# nW*B, window_size*wi\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m270 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# merge windows\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m271 \u001b[0m\u001b[2m│   │   \u001b[0mattn_windows = attn_windows.view(-\u001b[94m1\u001b[0m, \u001b[96mself\u001b[0m.window_size, \u001b[96mself\u001b[0m.window_size, C)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/projects/codeServerEPI/models/networks/\u001b[0m\u001b[1;33mswin_transformer.py\u001b[0m:\u001b[94m137\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   \u001b[0mrelative_position_bias = \u001b[96mself\u001b[0m.relative_position_bias_table[\u001b[96mself\u001b[0m.relative_positio   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.window_size[\u001b[94m0\u001b[0m] * \u001b[96mself\u001b[0m.window_size[\u001b[94m1\u001b[0m], \u001b[96mself\u001b[0m.window_size[\u001b[94m0\u001b[0m] * \u001b[96mself\u001b[0m.window   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   \u001b[0mrelative_position_bias = relative_position_bias.permute(\u001b[94m2\u001b[0m, \u001b[94m0\u001b[0m, \u001b[94m1\u001b[0m).contiguous()  \u001b[2m#\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m137 \u001b[2m│   │   \u001b[0mattn = attn + relative_position_bias.unsqueeze(\u001b[94m0\u001b[0m)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mask \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   \u001b[0mnW = mask.shape[\u001b[94m0\u001b[0m]                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using mini batch kemeans \n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import math\n",
    "import pickle\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "data,loader= get_data(pz = 24,img_size= 224,pz_=64,split='val')\n",
    "num_nodes = 168\n",
    "num_points = 700 if len(data) > 20000 else len(data)\n",
    "model2 = VAE(input_height=inp,window_size =28, patch_size = 4)\n",
    "vae = model2.load_from_checkpoint(\"/home/uz1/projects/GCN/logging/swin_vae/2023_03_16/epoch=0-step=3334.ckpt\",) # 80\n",
    "h=int(int(data[0][0].shape[-1]) * sqrt(data[0][0].shape[0]))\n",
    "p_z = int(sqrt((h*h) // int(data[0][0].shape[0])))\n",
    "num_points = num_points if (((h // p_z) * (h // p_z) ) * num_points ) % 16000 == 0 else 16000 // ((h // p_z) * (h // p_z))\n",
    "num_patches= (h // p_z) * (h // p_z)\n",
    "num_points = 16000 // (num_patches * loader.batch_size)\n",
    "print(\"given num_patches: \", num_patches, \" num_points: \", num_points)\n",
    "\n",
    "vae = vae.to('cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h = 224\n",
    "p_z = data[0][0].shape[-1]\n",
    "# print(\"Using a VAE with h=\",h,\"and p(z)=\",p_z)\n",
    "if loader.batch_size < num_nodes:\n",
    "    batch_size = num_nodes\n",
    "    loader = DataLoader(data, batch_size=batch_size, drop_last=True, num_workers=14)\n",
    "if not os.path.exists(f\"/home/uz1/projects/GCN/GraphGym/run/kmeans-model-{h}-{p_z}-{num_nodes}-{data.__class__.__name__}-swin.pkl\"):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_nodes)\n",
    "    for i in tqdm(range(num_points),total=num_points,desc=\"Fitting Kmeans\",):\n",
    "        test,_ = next(iter(loader))\n",
    "        test = test.to(vae.device)\n",
    "        if test.dim() >4:\n",
    "            test = test.reshape(-1, test.shape[2], test.shape[3], test.shape[4]) # batch, num patches ,channel, height, width to batch, channel, height, width\n",
    "        x_encoded = vae.encoder.forward_features(test)\n",
    "        mu, log_var = vae.fc_mu(x_encoded), vae.fc_var(x_encoded)\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        z=z.detach().cpu().numpy()\n",
    "        kmeans.partial_fit(z)\n",
    "    print(\"Done - out shape \",z.shape)\n",
    "    with open(f\"/home/uz1/projects/GCN/GraphGym/run/kmeans-model-{h}-{p_z}-{num_nodes}-{data.__class__.__name__}-swin.pkl\", 'wb') as f:\n",
    "        pickle.dump(kmeans, f)\n",
    "\n",
    "print(\"Kmeans Done !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bf7c8448272c4cbdce3f78384e0b31dc492bbd9290e96311fca142ad432e9ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
